name: Cold Email Infrastructure Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run tests daily at 3 AM UTC
    - cron: '0 3 * * *'
  workflow_dispatch:
    inputs:
      test_type:
        description: 'Type of tests to run'
        required: true
        default: 'all'
        type: choice
        options:
        - all
        - unit
        - integration
        - performance
        - migration
        - error_scenarios
      environment:
        description: 'Environment to test against'
        required: true
        default: 'testing'
        type: choice
        options:
        - testing
        - staging
        - production

env:
  PYTHON_VERSION: '3.11'
  POETRY_VERSION: '1.8.0'
  
jobs:
  # Setup and validation job
  setup:
    name: Setup and Validation
    runs-on: ubuntu-latest
    outputs:
      test-matrix: ${{ steps.test-matrix.outputs.matrix }}
      python-version: ${{ env.PYTHON_VERSION }}
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Full history for migration validation
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ env.PYTHON_VERSION }}-${{ hashFiles('**/poetry.lock') }}
    
    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root
    
    - name: Install project
      run: poetry install --no-interaction
    
    - name: Validate code structure
      run: |
        poetry run python -c "
        import sys
        sys.path.append('src/email-infrastructure')
        
        # Test imports of major systems
        try:
            from dns.managers.dns_manager import DNSManager
            from mailcow.core.api_client import MailcowAPI
            from vps.core.vps_manager import VPSManager
            from monitoring.monitors.blacklist_monitor import BlacklistMonitor
            from monitoring.campaigns.warmup_campaigns import WarmupCampaigns
            print('✅ All major systems importable')
        except ImportError as e:
            print(f'❌ Import error: {e}')
            sys.exit(1)
        "
    
    - name: Generate test matrix
      id: test-matrix
      run: |
        if [ "${{ github.event.inputs.test_type }}" = "unit" ]; then
          MATRIX='["unit"]'
        elif [ "${{ github.event.inputs.test_type }}" = "integration" ]; then
          MATRIX='["integration"]'
        elif [ "${{ github.event.inputs.test_type }}" = "performance" ]; then
          MATRIX='["performance"]'
        elif [ "${{ github.event.inputs.test_type }}" = "migration" ]; then
          MATRIX='["migration"]'
        elif [ "${{ github.event.inputs.test_type }}" = "error_scenarios" ]; then
          MATRIX='["error_scenarios"]'
        else
          MATRIX='["unit", "integration", "migration", "error_scenarios"]'
        fi
        echo "matrix=$MATRIX" >> $GITHUB_OUTPUT

  # Unit tests job
  unit-tests:
    name: Unit Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(needs.setup.outputs.test-matrix, 'unit')
    strategy:
      matrix:
        system: [dns, mailcow, vps, monitoring]
        python-version: ['3.9', '3.10', '3.11']
      fail-fast: false
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ matrix.python-version }}-${{ hashFiles('**/poetry.lock') }}
    
    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root --with test
    
    - name: Install project
      run: poetry install --no-interaction
    
    - name: Run unit tests for ${{ matrix.system }}
      run: |
        poetry run pytest tests/unit/test_${{ matrix.system }}/ \
          -v \
          --tb=short \
          --cov=src/email-infrastructure/${{ matrix.system }} \
          --cov-report=xml \
          --cov-report=html \
          --cov-fail-under=85 \
          --junit-xml=test-results/unit-${{ matrix.system }}-${{ matrix.python-version }}.xml \
          -m unit
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN_TEST }}
        MAILCOW_API_KEY: ${{ secrets.MAILCOW_API_KEY_TEST }}
        MAILCOW_HOSTNAME: test.mailcow.local
    
    - name: Upload test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: unit-test-results-${{ matrix.system }}-${{ matrix.python-version }}
        path: |
          test-results/
          htmlcov/
          coverage.xml
    
    - name: Upload coverage reports
      uses: codecov/codecov-action@v3
      if: matrix.python-version == '3.11'
      with:
        file: ./coverage.xml
        flags: unit,${{ matrix.system }}
        name: unit-${{ matrix.system }}

  # Integration tests job
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(needs.setup.outputs.test-matrix, 'integration')
    
    services:
      # Test database
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: testpass
          POSTGRES_DB: email_infrastructure_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      # Redis for caching tests
      redis:
        image: redis:7-alpine
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ needs.setup.outputs.python-version }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Load cached venv
      id: cached-poetry-dependencies
      uses: actions/cache@v3
      with:
        path: .venv
        key: venv-${{ runner.os }}-${{ needs.setup.outputs.python-version }}-${{ hashFiles('**/poetry.lock') }}
    
    - name: Install dependencies
      if: steps.cached-poetry-dependencies.outputs.cache-hit != 'true'
      run: poetry install --no-interaction --no-root --with test
    
    - name: Install project
      run: poetry install --no-interaction
    
    - name: Setup test environment
      run: |
        # Create test directories
        mkdir -p test-data/{dns,mailcow,vps,monitoring}
        mkdir -p test-logs
        
        # Setup test configurations
        cp tests/config/test_config.yaml test-data/
    
    - name: Run integration tests
      run: |
        poetry run pytest tests/integration/ \
          -v \
          --tb=short \
          --cov=src/email-infrastructure \
          --cov-report=xml \
          --cov-append \
          --junit-xml=test-results/integration.xml \
          -m integration
      env:
        DATABASE_URL: postgresql://postgres:testpass@localhost:5432/email_infrastructure_test
        REDIS_URL: redis://localhost:6379/0
        RUN_INTEGRATION_TESTS: true
        TEST_TIMEOUT: 60
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN_TEST }}
        MAILCOW_API_KEY: ${{ secrets.MAILCOW_API_KEY_TEST }}
        MAILCOW_HOSTNAME: test.mailcow.local
    
    - name: Upload integration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: integration-test-results
        path: |
          test-results/
          test-logs/

  # Migration integrity tests
  migration-tests:
    name: Migration Integrity Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(needs.setup.outputs.test-matrix, 'migration')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0  # Need full history for migration validation
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ needs.setup.outputs.python-version }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-root --with test
        poetry install --no-interaction
    
    - name: Run migration integrity validation
      run: |
        poetry run pytest tests/migration/test_migration_integrity.py \
          -v \
          --tb=short \
          --junit-xml=test-results/migration.xml \
          -m migration
    
    - name: Generate migration report
      if: always()
      run: |
        poetry run python tests/migration/test_migration_integrity.py > migration-report.txt
    
    - name: Upload migration test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: migration-test-results
        path: |
          test-results/
          migration-report.txt

  # Performance tests job
  performance-tests:
    name: Performance Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(needs.setup.outputs.test-matrix, 'performance') || github.event.schedule
    timeout-minutes: 30
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ needs.setup.outputs.python-version }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-root --with test
        poetry install --no-interaction
        # Install performance testing dependencies
        poetry run pip install memory-profiler psutil
    
    - name: Run performance benchmarks
      run: |
        poetry run pytest tests/performance/test_performance_benchmarks.py \
          -v \
          --tb=short \
          --junit-xml=test-results/performance.xml \
          -m performance \
          --durations=0
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN_TEST }}
        MAILCOW_API_KEY: ${{ secrets.MAILCOW_API_KEY_TEST }}
        MAILCOW_HOSTNAME: test.mailcow.local
    
    - name: Generate performance report
      if: always()
      run: |
        echo "## Performance Test Results" > performance-report.md
        echo "Generated at: $(date)" >> performance-report.md
        echo "" >> performance-report.md
        
        # Extract performance metrics from test output
        if [ -f test-results/performance.xml ]; then
          echo "Performance tests completed successfully" >> performance-report.md
        else
          echo "Performance tests failed or were skipped" >> performance-report.md
        fi
    
    - name: Upload performance test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: performance-test-results
        path: |
          test-results/
          performance-report.md

  # Error scenario tests
  error-scenario-tests:
    name: Error Scenario Tests
    runs-on: ubuntu-latest
    needs: setup
    if: contains(needs.setup.outputs.test-matrix, 'error_scenarios')
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ needs.setup.outputs.python-version }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-root --with test
        poetry install --no-interaction
    
    - name: Run error scenario tests
      run: |
        poetry run pytest tests/error_scenarios/ \
          -v \
          --tb=short \
          --cov=src/email-infrastructure \
          --cov-report=xml \
          --cov-append \
          --junit-xml=test-results/error-scenarios.xml
      env:
        CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN_TEST }}
        MAILCOW_API_KEY: ${{ secrets.MAILCOW_API_KEY_TEST }}
        MAILCOW_HOSTNAME: test.mailcow.local
    
    - name: Upload error scenario test results
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: error-scenario-test-results
        path: |
          test-results/
          coverage.xml

  # Security and code quality
  security-scan:
    name: Security and Code Quality
    runs-on: ubuntu-latest
    needs: setup
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ needs.setup.outputs.python-version }}
    
    - name: Install Poetry
      uses: snok/install-poetry@v1
      with:
        version: ${{ env.POETRY_VERSION }}
        virtualenvs-create: true
        virtualenvs-in-project: true
    
    - name: Install dependencies
      run: |
        poetry install --no-interaction --no-root --with dev
        poetry install --no-interaction
    
    - name: Run security scan with bandit
      run: |
        poetry run bandit -r src/email-infrastructure/ -f json -o security-report.json || true
    
    - name: Run code quality checks
      run: |
        # Type checking with mypy
        poetry run mypy src/email-infrastructure/ --ignore-missing-imports --report mypy-report || true
        
        # Code style with flake8
        poetry run flake8 src/email-infrastructure/ --format=json --output-file=flake8-report.json || true
        
        # Security check with safety
        poetry run safety check --json --output safety-report.json || true
    
    - name: Upload security and quality reports
      uses: actions/upload-artifact@v3
      if: always()
      with:
        name: security-quality-reports
        path: |
          security-report.json
          mypy-report/
          flake8-report.json
          safety-report.json

  # Generate final test report
  test-report:
    name: Generate Test Report
    runs-on: ubuntu-latest
    needs: [setup, unit-tests, integration-tests, migration-tests, performance-tests, error-scenario-tests, security-scan]
    if: always()
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Download all test artifacts
      uses: actions/download-artifact@v3
    
    - name: Generate comprehensive test report
      run: |
        echo "# Cold Email Infrastructure Test Report" > test-report.md
        echo "Generated at: $(date)" >> test-report.md
        echo "" >> test-report.md
        
        echo "## Test Summary" >> test-report.md
        echo "| Test Type | Status |" >> test-report.md
        echo "|-----------|--------|" >> test-report.md
        
        # Check unit tests
        if ls unit-test-results-*/test-results/*.xml 1> /dev/null 2>&1; then
          echo "| Unit Tests | ✅ Passed |" >> test-report.md
        else
          echo "| Unit Tests | ❌ Failed or Skipped |" >> test-report.md
        fi
        
        # Check integration tests
        if ls integration-test-results/test-results/integration.xml 1> /dev/null 2>&1; then
          echo "| Integration Tests | ✅ Passed |" >> test-report.md
        else
          echo "| Integration Tests | ❌ Failed or Skipped |" >> test-report.md
        fi
        
        # Check migration tests
        if ls migration-test-results/test-results/migration.xml 1> /dev/null 2>&1; then
          echo "| Migration Tests | ✅ Passed |" >> test-report.md
        else
          echo "| Migration Tests | ❌ Failed or Skipped |" >> test-report.md
        fi
        
        # Check performance tests
        if ls performance-test-results/test-results/performance.xml 1> /dev/null 2>&1; then
          echo "| Performance Tests | ✅ Passed |" >> test-report.md
        else
          echo "| Performance Tests | ❌ Failed or Skipped |" >> test-report.md
        fi
        
        # Check error scenario tests
        if ls error-scenario-test-results/test-results/error-scenarios.xml 1> /dev/null 2>&1; then
          echo "| Error Scenario Tests | ✅ Passed |" >> test-report.md
        else
          echo "| Error Scenario Tests | ❌ Failed or Skipped |" >> test-report.md
        fi
        
        echo "" >> test-report.md
        echo "## Test Details" >> test-report.md
        
        # Add migration report if available
        if [ -f migration-test-results/migration-report.txt ]; then
          echo "### Migration Integrity Report" >> test-report.md
          echo '```' >> test-report.md
          cat migration-test-results/migration-report.txt >> test-report.md
          echo '```' >> test-report.md
        fi
        
        # Add performance report if available
        if [ -f performance-test-results/performance-report.md ]; then
          echo "### Performance Report" >> test-report.md
          cat performance-test-results/performance-report.md >> test-report.md
        fi
        
        echo "" >> test-report.md
        echo "## Coverage Summary" >> test-report.md
        
        # Combine coverage reports if available
        if ls */coverage.xml 1> /dev/null 2>&1; then
          echo "Coverage reports generated. See artifacts for detailed coverage information." >> test-report.md
        else
          echo "No coverage reports available." >> test-report.md
        fi
    
    - name: Upload final test report
      uses: actions/upload-artifact@v3
      with:
        name: comprehensive-test-report
        path: test-report.md
    
    - name: Comment PR with test results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('test-report.md')) {
            const report = fs.readFileSync('test-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });
          }

  # Deployment validation (only on main branch)
  deployment-validation:
    name: Deployment Validation
    runs-on: ubuntu-latest
    needs: [unit-tests, integration-tests, migration-tests]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    environment: staging
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Validate deployment readiness
      run: |
        echo "✅ All critical tests passed"
        echo "✅ Migration integrity validated"
        echo "✅ System ready for deployment"
    
    - name: Create deployment tag
      if: success()
      run: |
        git config --global user.name 'GitHub Actions'
        git config --global user.email 'actions@github.com'
        
        # Create deployment tag with timestamp
        TAG="deploy-$(date +%Y%m%d-%H%M%S)"
        git tag -a "$TAG" -m "Deployment candidate - all tests passed"
        
        echo "Created deployment tag: $TAG"
        echo "DEPLOYMENT_TAG=$TAG" >> $GITHUB_ENV